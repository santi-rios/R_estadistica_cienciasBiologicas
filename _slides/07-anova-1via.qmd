---
title: "ANOVA de una vía en R"
author:
  - name: "Mtro. Santiago Ríos"
    email: santiagoboo99@gmail.com
    affiliation: 
      - name: Cursos Orca
        city: CDMX
        url: orcaasesina.com
format: 
    live-html:
        highlightStyle: github
        highlightLines: true
        theme: superhero
toc: true
sidebar: false
webr:
    packages: 
        - tidyverse
        - ggpubr
        - car
        - ez
    render-df: gt-interactive
engine: knitr
---


{{< include ../_extensions/r-wasm/live/_knitr.qmd >}}

## Introducción

- En el análisis de varianza (ANOVA), cuando hablamos de *vías*, nos referimos al número de factores que estamos considerando.
- Recuerda que un factor es una variable categórica que define las diferentes categorías o niveles de un experimento. Por ejemplo, en un estudio sobre el efecto de diferentes tipos de fertilizantes en el crecimiento de plantas, el factor sería el tipo de fertilizante.
- Nuestro objetivo es determinar si las medias de los grupos son estadísticamente diferentes entre sí. 

## Datos

- Vamos a utilizar los datos del paquete `datos` llamados `diamantes`. Estos datos contienen información sobre el precio de los diamantes en función de diferentes características.

```{webr}
#| autorun: true
#| warning: false


library(datos)

salarios
```

## Pregunta de investigación e hipótesis

- Queremos saber si hay diferencias significativas en el precio (variable `precio`) de los diamantes en función de la corte (variable `corte`) de los mismos.
- La hipótesis nula ($H_0$) es que no hay diferencias significativas en el precio de los diamantes en función de la corte.
- La hipótesis alternativa ($H_1$) es que hay diferencias significativas en el precio de los diamantes en función de la corte.

## Visualización preliminar

- Antes de realizar el ANOVA, es útil visualizar los datos para tener una idea de cómo se distribuyen.

```{webr}
#| autorun: true
#| warning: false

library(ggplot2)

ggplot(diamantes, aes(x = corte, y = precio)) +
  geom_boxplot() +
  labs(title = "Precio de los diamantes por corte")

```

::: {.callout}
como ves, es más difícil darnos una idea de la distribución de los datos, por lo que es necesario realizar un ANOVA para determinar si hay diferencias significativas.

:::

## Supuestos del ANOVA

- antes de realizar un ANOVA, es importante verificar que se cumplan los siguientes supuestos:
    - Normalidad: los residuos deben seguir una distribución normal.
    - Homogeneidad de varianzas: los grupos deben tener varianzas similares.
    - Independencia: las observaciones deben ser independientes entre sí.

**Normalidad**

- Podemos verificar la normalidad de los residuos utilizando la prueba de Shapiro-Wilk y/o con un gráfico Q-Q.

::: {.callout-tip}
## OJO

- De acuerdo al teorema del límite central, el ANOVA es robusto a la violación de la normalidad si el tamaño de la muestra es grande (n > 30).
- En nuestros datos, tenemos una `n > 5000`, por lo que no es necesario que los datos sigan una distribución normal.
- De hecho, si intentas usar la prueba de Shapiro-Wilk, obtendrás un error debido al tamaño de la muestra.
:::

```{webr}

# Gráfico Q-Q
library(ggpubr)
ggqqplot(diamantes, x = "precio", color = "corte")


# Prueba de Shapiro-Wilk
shapiro.test(diamantes$precio)

```

::: {.callout-note}

El método visual parece indicar que los datos no siguen una distribución normal. Sin embargo, debido al tamaño de la muestra, no es necesario que los datos sigan una distribución normal para realizar un ANOVA. Sin embargo, más adelante veremos qué hacer si los datos no siguen una distribución normal.

:::

**Homogeneidad de varianzas**

- Podemos verificar la homogeneidad de varianzas utilizando la prueba de Levene.
  - $H_0$: Las varianzas son iguales.
  - $H_1$: Al menos una de las varianzas es diferente. 
- Para esto, necesitamos instalar y cargar el paquete `car`, el cual contiene la función `leveneTest()`.

```{webr}
#| autorun: true
#| warning: false

library(car)

leveneTest(precio ~ corte, data = diamantes)

```

::: {.callout}

## Resultados

**Grados de libertad** (Df):

- El primer valor (4) se refiere a los grados de libertad entre grupos.
- El segundo valor (53935) se refiere a los grados de libertad dentro de los grupos.

**Valor F** (F value): 123.595

- Este es el estadístico de la prueba de Levene. 
- Un valor alto sugiere diferencias significativas entre las varianzas de los grupos.

**Valor P** (Pr(>F)): 3.36 \times 10^{-105}3.36×10 
−105

- Este valor es extremadamente pequeño, mucho menor que el umbral típico de significancia ($\alpha = 0.05$).

**Conclusión**

>Dado que el valor p es mucho menor que 0.05, rechazamos la hipótesis nula de homogeneidad de varianzas. Esto indica que hay diferencias significativas entre las varianzas de los grupos, sugiriendo que las varianzas no son iguales.

:::

Como vemos, no se cumplen los supuestos de normalidad y homogeneidad de varianzas. Sin embargo, debido al tamaño de la muestra, podemos proceder con el ANOVA, aunque los resultados pueden no ser confiables y debes reportar en tu tesis/artículo que no se cumplen los supuestos. En la siguiente lección veremos qué hacer si no se cumplen los supuestos. Por el momento, vamos a realizar el ANOVA.

## ANOVA de una vía

- Para realizar el ANOVA, tenemos varias formas de hacerlo:
  - Usando la función `aov()`, la cual es parte del paquete base de R.
  - Usando la función `lm()` (modelo lineal). Como ya vimos en el curso, el ANOVA es una forma especial de regresión lineal. Por lo tanto, podemos usar `lm()` para realizar un ANOVA. 
  - Con la función `ezANOVA()` del paquete `ez`. Esta función es útil para realizar ANOVAs de una manera más sencilla y rápida.
- Vamos a ver los 3 ejemplos anteriores.

### Usando `aov()`

- La función `aov()` es la forma más común de realizar un ANOVA en R.
- La sintaxis es `aov(y ~ x, data = df)`, donde `y` es la variable dependiente, `x` es la variable independiente y `df` es el conjunto de datos.
- Para obtener un resumen del ANOVA, usamos la función `summary()`.
- Vamos a realizar el ANOVA con la variable `precio` como variable dependiente y `corte` como variable independiente.

```{webr}
#| autorun: true
#| warning: false

modelo_aov <- aov(precio ~ corte, data = diamantes)

summary(modelo_aov)

```

::: {.callout}

En el resultado, tenemos:
- **Df**: Grados de libertad.
- **Sum Sq**: Suma de cuadrados.
- **Mean Sq**: Media de cuadrados.
- **F value**: Valor F.
- **Pr(>F)**: Valor p.
- **Residuals**: Residuos. Estos son los errores (diferencias entre los valores observados y los valores predichos por el modelo).
- **Signif. codes**: Códigos de significancia (*** para p < 0.001, ** para p < 0.01, * para p < 0.05).

En nuestro ejemplo, el valor p es menor que 0.05, lo que indica que hay diferencias significativas en el precio de los diamantes en función de la corte.

:::

### Usando `lm()`

- Como mencionamos anteriormente, el ANOVA es una forma especial de regresión lineal. Por lo tanto, podemos usar la función `lm()` para realizar un ANOVA.
- La sintaxis es similar a la de `aov()`, pero en lugar de usar `aov()`, usamos `lm()`.
- Para obtener un resumen del ANOVA, usamos la función `anova()`. Observa que NO usamos `aov()`, sino `anova()`. 
- La ventaja de usar `lm()` es que podemos obtener más información sobre el modelo con la función `summary()`. Observa que el valor F y el valor p son los mismos que en el ANOVA con `aov()`.

```{webr}
#| autorun: true
#| warning: false

modelo_lm <- lm(precio ~ corte, data = diamantes)

anova(modelo_lm)

summary(modelo_lm)

```

::: {.callout}
## Ventajas de `lm()`

- Con `lm()`, podemos obtener más información sobre el modelo, como los coeficientes de regresión, el coeficiente de determinación (R²), etc.
- Muchos de estos conceptos van más allá del objetivo del curso, pero es útil saber que `lm()` proporciona más información detallada sobre el modelo.
- Veamos qué significa la salida:


### Call

- **Call**: Muestra la fórmula utilizada para el modelo lineal: `precio ~ corte`, donde `precio` es la variable dependiente y `corte` es la variable independiente.

### Residuals

- **Min, 1Q, Median, 3Q, Max**: Estos valores resumen la distribución de los residuos. Valores extremos pueden indicar la presencia de outliers o ciertas asimetrías.
- Idealmente, los residuos deberían seguir una distribución normal, donde la mediana es cercana a cero y los cuartiles son simétricos.

### Coefficients

> en el contexto de un modelo lineal, los coeficientes representan la relación entre la variable independiente y la variable dependiente. Los coeficientes te ayudan a entender cómo diferentes niveles de corte afectan el precio.
> Te permiten predecir el precio para diferentes niveles de corte al insertar estos valores en la ecuación del modelo lineal.
> En este caso, los coeficientes representan la diferencia en el precio para cada nivel de corte en comparación con el nivel de referencia (corte Regular). Por lo tanto, el coeficiente para corte.L es la diferencia en el precio entre corte Ideal y corte Regular, y así sucesivamente. Puedes ver los contrastes entre los niveles de corte en la tabla de coeficientes:

```{webr}
#| autorun: true
#| warning: false

contr.treatment(levels(diamantes$corte))

```

- **Estimate**: Es la estimación del coeficiente para cada nivel del factor `corte`. 
  - `(Intercept)`: Representa el valor esperado de la variable dependiente (precio) cuando todas las variables independientes son cero. En este caso, es el valor promedio del precio para el nivel de referencia del factor corte.
  - `corte.L`, `corte.Q`, `corte.C`, `corte^4`: Son los coeficientes para los contrastes de los niveles del factor `corte`. En un análisis de regresión con un factor categórico, se utilizan contrastes para representar diferencias entre niveles.
    - Cada coeficiente indica el cambio en la respuesta (precio) asociado con un cambio en el nivel del factor corte, ajustado por otros niveles.
  - Un coeficiente positivo indica que un aumento en el nivel del factor corte se asocia con un aumento en el precio. Un coeficiente negativo indica que un aumento en el nivel del factor corte se asocia con una disminución en el precio.
  - **Magnitud del Coeficiente**: Cuanto mayor sea el valor absoluto del coeficiente, mayor será el impacto del nivel del factor en el precio.

- **Std. Error**: Error estándar de cada coeficiente, que indica la precisión de la estimación.

- **t value**: Estadístico t para cada coeficiente, calculado como el coeficiente dividido por su error estándar. No necesitas preocuparte por este valor en este contexto, pero se utiliza para calcular el valor p.

- **Pr(>|t|)**: Valor p asociado con el estadístico t. Un valor p pequeño (usualmente < 0.05) indica que el coeficiente es significativamente diferente de cero.
  - Todos los coeficientes tienen valores p muy bajos (marcados con `***`), lo que indica que son estadísticamente significativos. Es decir, los diferentes niveles de corte tienen un efecto significativo en el precio.

### Significance Codes
- Los asteriscos indican el nivel de significancia de cada coeficiente: 
  - `***` para < 0.001
  - `**` para < 0.01
  - `*` para < 0.05

### Statistical Measures
- **Residual standard error**: 3964, que mide la desviación estándar de los residuos.
- **Multiple R-squared**: 0.01286, indica la proporción de la varianza explicada por el modelo. Un valor bajo sugiere que el modelo no explica mucho la variabilidad de `precio`. En este caso, solo el 1.29% de la variabilidad de `precio` se explica por `corte`, lo que es bastante bajo. Esto sugiere que `corte` no es un predictor fuerte de `precio` y podríamos necesitar considerar otras variables (como `claridad`, `color`, etc.) para mejorar el ajuste del modelo.
- **Adjusted R-squared**: 0.01279, ajusta el R-squared para el número de predictores en el modelo. Este valor es importante cuando se comparan modelos con diferentes números de predictores.
- **F-statistic**: 175.7, prueba global para determinar si al menos un coeficiente es diferente de cero.
- **p-value**: < 2.2e-16, indica que el modelo en conjunto es significativo. Este valor es idéntico al valor p que obtuvimos en el ANOVA con `aov()`.

### Conclusión

El modelo es significativo en general, pero el valor R-cuadrado bajo sugiere que `corte` no explica bien la variabilidad del `precio`. Podría ser útil considerar otras variables o transformar las existentes para mejorar el ajuste del modelo.

:::

### Usando `ezANOVA()`

- Para usar `ezANOVA()`, primero necesitamos instalar y cargar el paquete `ez`.
- En un principio, parece que este método es más complejo que los anteriores, debido a que:
  - Debemos especificar la variable dependiente (`dv`), la variable independiente (`between`) y la variable de agrupamiento (`wid`). En este caso, no tenemos una variable de agrupamiento, por lo que tenemos que crearla.
  - Sin embargo, cuando veamos diseños más complejos, como ANOVAs de dos vías, ANOVA mixtos, ANOVA de medidas repetidas, etc., `ezANOVA()` será más fácil de usar.
- Aunque el valor de F calculado con los 3 métodos es idéntico, el valor p es más detallado en `ezANOVA()`.

```{webr}
#| autorun: true
#| warning: false

# install.packages("ez")
library(ez)

# Asegúrate de que 'diamantes' sea un data frame y que 'corte' sea un factor
diamantes$corte <- as.factor(diamantes$corte)

# Crear identificador único para cada observación
diamantes$ID <- 1:nrow(diamantes)

# Realizar el ANOVA
resultados <- ezANOVA(
  data = diamantes,
  dv = .(precio),
  wid = .(ID),    # Necesitas un identificador único para cada observación
  between = .(corte),
  type = 3
)

# Mostrar los resultados
print(resultados)

```


::: {.callout-note}

Vamos a ver qué significa el código anterior y la salida:

- Primero, instalamos y cargamos el paquete `ez`.
- Luego, nos aseguramos que `diamantes` sea un data frame y que `corte` sea un factor. Esto es necesario para `ezANOVA()` y que no haya errores. 
- Luego, creamos un identificador único para cada observación en `diamantes`. Esto es necesario para `ezANOVA()`. En los diseños más complejos, es importante identificar si hay observaciones pareadas o emparejadas (p. ej., mediciones en el mismo sujeto en diferentes momentos).
- Después, usamos `ezANOVA()` para realizar el ANOVA. 
  - `data`: El conjunto de datos.
  - `dv`: La variable dependiente (`precio`).
  - `wid`: El identificador único para cada observación.
  - `between`: La variable independiente (`corte`).
    - ***Ojo***: En el contexto de ANOVA, las variables pueden ser clasificadas como **between-subjects** o **within-subjects**, y cada una se utiliza en diferentes diseños experimentales.
    - Between-Subjects: Cada grupo de participantes o unidades experimentales está expuesto a un solo nivel de la variable independiente. Los comparaciones se hacen entre grupos. Ejemplo: En un estudio de medicamentos, un grupo recibe el medicamento y otro grupo recibe un placebo. Cada participante está en un solo grupo. Between-Subjects: Se enfoca en variabilidad entre grupos diferentes.
    - Within-Subjects: Las mismas unidades experimentales están expuestas a todos los niveles de la variable independiente. Las comparaciones se hacen dentro de los mismos sujetos o unidades. Las variables within-subjects son más comunes en estudios que involucran medidas repetidas sobre las mismas unidades. Within-Subjects: Se enfoca en variabilidad dentro del mismo grupo a través de condiciones.
    - Hay modelos que incoporan ambos tipos de variables, como ANOVA de medidas repetidas, ANOVA mixtos, etc. Se verán en lecciones posteriores.
  - `type = 3`: Especifica el tipo de ANOVA. El tipo 3 es el tipo de sumas de cuadrados más comúnmente usado en ANOVA y se recomienda cuando tienes un diseño no balanceado (es decir, diferentes tamaños de muestra en cada grupo, que suele ser el caso en la mayoría de los experimentos).



- Finalmente, mostramos los resultados.
- La salida de `ezANOVA()` es similar a la de `aov()`, pero con un formato más fácil de leer.
- En este caso, el valor p es menor que 0.05, lo que indica que hay diferencias significativas en el precio de los diamantes en función de la corte.

:::

## Gráficos informativos

### Boxplot y p-value del ANOVA


```{webr}
#| autorun: true
#| warning: false

library(ggpubr)


ggboxplot(diamantes, x = "corte", y = "precio",
          color = "corte", palette = "jco")+
  stat_compare_means(method = "anova")
```

### Gráfico de barras con comparaciones múltiples

- En el gráfico anterior, vimos que hay diferencias significativas en el precio de los diamantes en función de la corte (de acuerdo al ANOVA).
- Para ver cuáles son las diferencias significativas entre los niveles de corte, podemos realizar comparaciones múltiples.
- Como estamos realizando múltiples comparaciones, es importante ajustar el nivel de significancia para evitar falsos positivos. Una forma común de hacer esto es con el método de Tukey, o el método de Bonferroni (no recomendado para más de 3 comparaciones), el método de Holm-Bonferroni, etc. Por el momento, no vamos a ajustar el nivel de significancia. Esto se verá en las proximas lecciones.
  - Podemos hacer las comparaciones de distintas formas: comparar cada posible par de niveles, comparar cada nivel con un nivel de referencia, etc. Por simplicidad, vamos a comparar cada nivel con el nivel de referencia (corte Ideal). Esto se hace con la función `stat_compare_means()` y especificando el método como `t.test` y el grupo de referencia como `Ideal`. Como resultado, obtendremos las diferencias significativas entre los niveles de corte *vs* el nivel de referencia "Ideal".

```{webr}
#| autorun: true
#| warning: false

ggboxplot(diamantes, x = "corte", y = "precio",
          color = "corte", palette = "jco")+
  stat_compare_means(method = "anova", label.y = 20000) + # anova global
  stat_compare_means(label = "p.signif", method = "t.test",
                     ref.group = "Ideal") # comparaciones múltiples
```


::: {.callout-important}

En las siguientes lecciones, veremos cómo realizar el ANOVA, el gráfico, y las comparaciones múltiples en un solo paso con la función `anova_test()` del paquete `rstatix`. Esta función es muy similar a `ezANOVA()`, pero es un poco más fácil de usar en los gráficos.
:::